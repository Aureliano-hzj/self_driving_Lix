Index: lane_detection/image_processing.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import cv2\r\nfrom .parameters import *\r\nimport cv2\r\n\r\nfrom .parameters import *\r\n\r\n\r\nclass image_feature:\r\n    \"\"\"\r\n    The class takes in an image matrix and can do multiple openCV operations on the image.\r\n    \"\"\"\r\n    def __init__(self, img):\r\n        \"\"\"\r\n        The initialization takes in an image matrix.\r\n        For 2-dim images, format must be GRAY;\r\n        for 3-dim images, format must be BGR.\r\n\r\n        :param img: 2-dim or 3-dim image matrix\r\n        \"\"\"\r\n\r\n    def channel_selection(self, label):\r\n        \"\"\"TODO: Get the specified channel image.\"\"\"\r\n\r\n    def binary_threshold(self, thresholds):\r\n        \"\"\"TODO: Create a binary image, in which 0 refers to the region within the thresholds. \"\"\"\r\n\r\n    def gaussian_blur(self, sigma, k_size=3):\r\n        \"\"\"TODO: Use a Gaussian Kernel to blur the image\"\"\"\r\n\r\n    def sobel_convolute(self, method, k_size=3):\r\n        \"\"\"TODO: Use a Sobel kernel to calculate the derivative of the image.\"\"\"\r\n\r\n    def __and__(self, other):\r\n        \"\"\"TODO: Return the bitwise-and result of 2 image matrices\"\"\"\r\n\r\n    def __or__(self, other):\r\n        \"\"\"TODO: Return the bitwise-or result of 2 image matrices\"\"\"\r\n\r\n    def __xor__(self, other):\r\n        \"\"\"TODO: Return the bitwise-xor result of 2 images matrices\"\"\"\r\n\r\n    def __add__(self, other):\r\n        \"\"\"TODO: Combine the 2 image features by setting them to 2 color channels.\"\"\"\r\n\r\n\r\nclass feature_collector:\r\n    \"\"\"\r\n    Collects a list of features extracted from a single image.\r\n    Use them for showing, combination, or simply acts as a pipeline.\r\n    :self.attribute img: the BGR or GRAY image matrix\r\n    :self.attribute feature_dict: list of image_feature instance\r\n    :self.attribute color_model: the color model of image\r\n    \"\"\"\r\n\r\n    def __init__(self, img, color_model='BGR'):\r\n        \"\"\"\r\n        The initialization takes in an image matrix.\r\n        Acceptable formats including:\r\n            GRAY scale\r\n            all validate color formats supported by openCV\r\n        Images would be in default stored as uint8 format in BGR or GRAY.\r\n        If the format is not BGR for a 3-dim image, a [format] must be assigned.\r\n\r\n        :param img: 2-dim or 3-dim image matrix\r\n        :param color_model: labels among: BAYER_BG, HLS, HSV, LAB, RGB, BGR, GRAY...\r\n        \"\"\"\r\n        self.img = img\r\n        self.feature_dict = dict(origin=img.copy())\r\n        self.normalize()\r\n        if len(img.shape) == 2:\r\n            self.color_model = 'GRAY'\r\n        elif color_model != 'BGR':\r\n            l_valid_color_format = [key for key in cv2.__dict__.keys()\r\n                                    if key.startswith('COLOR')\r\n                                    and key.endswith('2BGR')\r\n                                    and len(key.split('_')) == 2]\r\n            if color_model in l_valid_color_format:\r\n                cvt_method = \"cv2.COLOR_\"+color_model+\"2BGR\"\r\n                self.img = cv2.cvtColor(self.img, eval(cvt_method))\r\n            else:\r\n                print('Unknown color model, please manually transfer to BGR.')\r\n        self.color_model = 'BGR'\r\n\r\n    def normalize(self):\r\n        \"\"\"TODO: Normalize the image.\"\"\"\r\n\r\n    def add_feature(self, key):\r\n        \"\"\"TODO: Add a new image_feature instance to the self.feature_dict by the key.\"\"\"\r\n\r\n    def __call__(self, method='and', **kwargs):\r\n        \"\"\"TODO: Combine all features in the self.feature_dict by the method.\"\"\"\r\n\r\n\r\ndef region_of_interest(img, vertices):\r\n    \"\"\"\r\n    Creates an image mask.\r\n\r\n    Only keeps the region of the image defined by the polygon\r\n    formed from `vertices`. The rest of the image is set to black.\r\n    `vertices` should be a numpy array of integer points.\r\n    \"\"\"\r\n    # defining a blank mask to start with\r\n    mask = np.zeros_like(img)\r\n\r\n    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\r\n    if len(img.shape) > 2:\r\n        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\r\n        ignore_mask_color = (255,) * channel_count\r\n    else:\r\n        ignore_mask_color = 255\r\n\r\n    # filling pixels inside the polygon defined by \"vertices\" with the fill color\r\n    cv2.fillPoly(mask, vertices, ignore_mask_color)\r\n\r\n    # returning the image only where mask pixels are nonzero\r\n    masked_image = cv2.bitwise_and(img, mask)\r\n    return masked_image\r\n\r\n\r\ndef line_vertices(img_BGR):\r\n    \"\"\"\r\n    Accepts an RGB image array, return a tuple of (lines, vertices) for region selection.\r\n\r\n    Input:\r\n    img_RGB: 3-tunnel image array, with size of Height * Width * Tunnels\r\n\r\n    Output:\r\n    lines: cordinates list of all lines to be drawn, size: 1 * Number_of_Lines * 4\r\n    vertices: cordinates numpy array of all vertices, size: 1 * Number_of_Vertices * 2\r\n    \"\"\"\r\n    y_max, x_max, _ = img_BGR.shape\r\n    # Assign cordinates for the 4 corners\r\n    Point_Lower_Left = (round(0.05 * x_max), y_max - 1)\r\n    Point_Lower_Right = (round(0.98 * x_max), y_max - 1)\r\n    Point_Upper_Left = (round(0.45 * x_max), round(0.6 * y_max))\r\n    Point_Upper_Right = (round(0.55 * x_max), round(0.6 * y_max))\r\n    Point_list = [Point_Lower_Left, Point_Lower_Right,\r\n                  Point_Upper_Right, Point_Upper_Left]\r\n    line = []\r\n    vertices = []\r\n    for i in range(len(Point_list)):\r\n        line.append(Point_list[0] + Point_list[1])\r\n        vertices.append(Point_list[0])\r\n        Point_list = Point_list[1:] + Point_list[:1]\r\n    lines = [line]\r\n    vertices = np.array([vertices])\r\n    return (lines, vertices)\r\n\r\n\r\ndef sobel_mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255), dir_thresh=(0,np.pi/2)):\r\n    \"\"\"Use Sobel kernels to calculate the magnitude&direction of derivatives of an image.\r\n\r\n    :input: img: image object RGB/GRAY\r\n    :input: mag_thresh: tuple of magnitude thresholds\r\n    :input: dir_thresh: tuple of direction thresholds\r\n    :input: sobel_kernel: size of the sobel kernel\r\n\r\n    :output: output_img: pixels where the sobel magnitude and direction both fall in their thresholds.\r\n    \"\"\"\r\n    if len(img.shape) == 3:\r\n        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\r\n    elif len(img.shape) == 2:\r\n        img_gray = cv2.copy(img)\r\n    dx_img_sobel = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\r\n    dy_img_sobel = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\r\n    d_img_mag = np.sqrt(np.square(dx_img_sobel) + np.square(dy_img_sobel))\r\n    d_img_dir = np.arctan2(np.absolute(dy_img_sobel), np.absolute(dx_img_sobel))\r\n    d_img_mag_scaled = np.uint8(255 * d_img_mag / d_img_mag.max())\r\n    d_img_mag_bin = (d_img_mag_scaled > mag_thresh[0]) & (d_img_mag_scaled < mag_thresh[1])\r\n    d_img_dir_bin = (d_img_dir > dir_thresh[0]) & (d_img_dir < dir_thresh[1])\r\n    return np.uint8(d_img_mag_bin&d_img_dir_bin)*255\r\n\r\n\r\ndef hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\r\n    \"\"\"\r\n    `img` should be the output of a Canny transform.\r\n\r\n    Returns an image with hough lines drawn.\r\n    \"\"\"\r\n    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array(\r\n        []), minLineLength=min_line_len, maxLineGap=max_line_gap)\r\n    ##lane_line = hough2lane_lines(lines, img)\r\n    ##line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\r\n    ##draw_lines(line_img, lane_line)\r\n    return lines\r\n\r\n\r\ndef hough2lane_lines(hough_line_list, img):\r\n    \"\"\"\r\n    According to given hough lines, calculate 2 lane lines which averages lane lines on both sides.\r\n    \"\"\"\r\n    h_img, w_img, _ = img.shape\r\n    kl_min = -10\r\n    kl_max = -0.5\r\n    kr_min = 0.5\r\n    kr_max = 10\r\n\r\n    # Group all lines into 2 lists. Each line should be listed together with its k.\r\n    line_list_l = []\r\n    line_list_r = []\r\n\r\n    for hough_line in hough_line_list:\r\n        k = (hough_line[0][3]-hough_line[0][1])/(hough_line[0][2]-hough_line[0][0])\r\n        if k > kl_min and k < kl_max:\r\n            line_list_l.append(hough_line)\r\n        elif k > kr_min and k < kr_max:\r\n            line_list_r.append(hough_line)\r\n\r\n    # Average all ks\r\n    k_l = 0\r\n    k_r = 0\r\n    x_list_l = []\r\n    y_list_l = []\r\n    x_list_r = []\r\n    y_list_r = []\r\n\r\n    if len(line_list_l) > 0:\r\n        for line in line_list_l:\r\n            x_list_l.append(line[0][0])\r\n            x_list_l.append(line[0][2])\r\n            y_list_l.append(line[0][1])\r\n            y_list_l.append(line[0][3])\r\n            k_l = (max(y_list_l)-min(y_list_l))/(max(x_list_l)-min(x_list_l))\r\n\r\n    if len(line_list_r) > 0:\r\n        for line in line_list_r:\r\n            x_list_r.append(line[0][0])\r\n            x_list_r.append(line[0][2])\r\n            y_list_r.append(line[0][1])\r\n            y_list_r.append(line[0][3])\r\n            k_r = (max(y_list_r)-min(y_list_r))/(max(x_list_r)-min(x_list_r))\r\n\r\n    # To Do: Calculate the 2 x cordinates in the 2 lines to be returned\r\n    line_l = [0, h_img-1, 0, 0.6*h_img]\r\n    line_r = [w_img-1, h_img-1, w_img-1, 0.6*h_img]\r\n    if k_l != 0:\r\n        line_l[0] = min(x_list_l) - (line_l[1] - max(y_list_l))/k_l\r\n        line_l[2] = max(x_list_l) - (line_l[3] - min(y_list_l))/k_l\r\n    if k_r != 0:\r\n        line_r[0] = min(x_list_r) + (line_r[1] - min(y_list_r))/k_r\r\n        line_r[2] = max(x_list_r) + (line_r[3] - max(y_list_r))/k_r\r\n    line_l = [map(int,line_l)]\r\n    line_r = [map(int,line_r)]\r\n\r\n    return np.array([line_l, line_r])\r\n\r\n
===================================================================
--- lane_detection/image_processing.py	(revision 1e3e8a09ecedb6f1eea758373bbe44aea5aee016)
+++ cam_image_process/image_functions/image_process_pipeline.py	(date 1586550263419)
@@ -1,28 +1,87 @@
+"""Provide basic models to build up image pipelines."""
 import cv2
-from .parameters import *
-import cv2
+import numpy as np
+
+from . import helper
+
+
+class Canvas2:
+    """
+    The superclass for any single-channel image elements.
+    :self.attribute canvas: a numpy image matrix of the same size as the image to be processed.
+    """
+
+    def __init__(self, img):
+        """
+        set the self.img as a black image of the same size as img.
+        :param img: the feature image numpy matrix
+        """
+        self.canvas = np.zeros_like(img)
+
+    def calibration(self, camMtx, distCoe):
+        """
+        TODO: undistort the image using the provided parameters.
+        :param camMtx: the camera Matrix
+        :param distCoe: the distortion coefficient
+        """
+
+    def __and__(self, other):
+        """Return the bitwise-and result of 2 image matrices"""
+        return helper.image_normalization(np.logical_and(self.canvas, other.canvas))
+
+    def __or__(self, other):
+        """Return the bitwise-or result of 2 image matrices"""
+        return helper.image_normalization(np.logical_or(self.canvas, other.canvas))
+
+    def __xor__(self, other):
+        """Return the bitwise-xor result of 2 images matrices"""
+        return helper.image_normalization(np.logical_xor(self.canvas, other.canvas))
+
+    def __add__(self, other):
+        """Combine the 2 image features by setting them to 2 color channels."""
+        return helper.image_normalization(np.stack((self.canvas, other.canvas, np.zeros_like(self.canvas)), axis=2))
 
-from .parameters import *
 
+class Canvas3(Canvas2):
+    """
+    The superclass for any three-channel image elements.
+    :self.attribute canvas: an image matrix of the same size as the image to be processed.
+    :self.attribute canvas3: the original 3-channel BGR image matrix.
+    """
+    def Canvas2GRAY(self):
+        """Turn the Canvas to gray scale image."""
+        self.canvas = cv2.cvtColor(self.canvas, cv2.COLOR_BGR2GRAY)
+        return self
 
-class image_feature:
+    def __add__(self, other):
+        """Combine the 2 image features by setting them to 2 color channels."""
+        if len(self.canvas.shape)==3:self.Canvas2GRAY()
+        if len(self.canvas.shape)==3:other.Canvas2GRAY()
+        return Canvas2.__add__(self, other)
+
+
+class ImgFeature2(Canvas2):
     """
-    The class takes in an image matrix and can do multiple openCV operations on the image.
+    The class takes in a single-channel image matrix and can do multiple openCV operations on the image.
+    :self.attribute canvas: the feature image(single channel)
+    :self.attribute img: the original image(single channel)
     """
+
     def __init__(self, img):
         """
         The initialization takes in an image matrix.
         For 2-dim images, format must be GRAY;
         for 3-dim images, format must be BGR.
 
-        :param img: 2-dim or 3-dim image matrix
+        :param img: 2-dim image matrix
         """
+        Canvas2.__init__(self, img)
+        self.img = img
 
-    def channel_selection(self, label):
-        """TODO: Get the specified channel image."""
-
-    def binary_threshold(self, thresholds):
-        """TODO: Create a binary image, in which 0 refers to the region within the thresholds. """
+    def binary_threshold(self, thresholds=(0,255)):
+        """Create a binary image, in which 0 refers to the region within the thresholds. """
+        self.canvas = (self.canvas>thresholds[0])&(self.canvas<thresholds[1])
+        return self
 
     def gaussian_blur(self, sigma, k_size=3):
         """TODO: Use a Gaussian Kernel to blur the image"""
@@ -30,26 +89,65 @@
     def sobel_convolute(self, method, k_size=3):
         """TODO: Use a Sobel kernel to calculate the derivative of the image."""
 
-    def __and__(self, other):
-        """TODO: Return the bitwise-and result of 2 image matrices"""
+
+class ImgFeature3(Canvas3, ImgFeature2):
+    """
+    The class takes in a three-channel image matrix and append some channel generating image_functions
+    to the ImageFeature2 superclass.
+    :self.attribute img: the feature image(single channel)
+    """
+
+    def channel_selection(self, label):
+        """
+        Get the specified channel image.
+        :param label: Supported labels:
+                      ('R', 'G', 'B', 'H', 'L', 'S')
+        """
+
+        if label in 'BGR':
+            self.canvas = self.img[:,:,'BGR'.index(label)]
+        elif label in 'HLS':
+            self.canvas = cv2.cvtColor(self.img, cv2.COLOR_BGR2HLS)[:,:,'HLS'.index(label)]
+        else:
+            print("Sorry but this channel is not supported, return R channel instead.")
+        return self
+
+    def gaussian_blur(self, sigma, k_size=3):
+        """TODO: Use a Gaussian Kernel to blur the image"""
+
+
+class ImgMask2(Canvas2):
+    """
+    Create an binary image mask using different kinds of edge extraction techniques.
+    :self.attribute img: an image mask matrix of the same size as the image to be processed.
+    """
+
+    def __init__(self, img):
+        """TODO: inherits the canvas.__init__, instead generate a white image."""
 
-    def __or__(self, other):
-        """TODO: Return the bitwise-or result of 2 image matrices"""
+    def geometrical_mask(self, vertices):
+        """
+        TODO: mask out the region outside of the vertices.
+        :param vertices: numpy matrix of vertices, size: num_vertices x num_edges x 2
+        """
 
-    def __xor__(self, other):
-        """TODO: Return the bitwise-xor result of 2 images matrices"""
+    def straight_lines(self, vertices, color=255, thickness=6):
+        """TODO: Create a mask with lines drawn with the parameters provided."""
 
-    def __add__(self, other):
-        """TODO: Combine the 2 image features by setting them to 2 color channels."""
 
+class ImgMask3(Canvas3, ImgMask2):
+    """TODO: image mask in 3 channels"""
 
-class feature_collector:
+
+class FeatureCollector:
     """
     Collects a list of features extracted from a single image.
     Use them for showing, combination, or simply acts as a pipeline.
     :self.attribute img: the BGR or GRAY image matrix
-    :self.attribute feature_dict: list of image_feature instance
+    :self.attribute layers_dict: list of image_feature instance
     :self.attribute color_model: the color model of image
+    :self.attribute cameraMtx: camera matrix for calibration
+    :self.attribute dist_coef: distortion coefficients for calibration
     """
 
     def __init__(self, img, color_model='BGR'):
@@ -64,10 +162,10 @@
         :param img: 2-dim or 3-dim image matrix
         :param color_model: labels among: BAYER_BG, HLS, HSV, LAB, RGB, BGR, GRAY...
         """
-        self.img = img
-        self.feature_dict = dict(origin=img.copy())
-        self.normalize()
-        if len(img.shape) == 2:
+
+        self.img = helper.image_normalization(img)
+        self.layers_dict = {}
+        if len(self.img.shape) == 2:
             self.color_model = 'GRAY'
         elif color_model != 'BGR':
             l_valid_color_format = [key for key in cv2.__dict__.keys()
@@ -75,20 +173,58 @@
                                     and key.endswith('2BGR')
                                     and len(key.split('_')) == 2]
             if color_model in l_valid_color_format:
-                cvt_method = "cv2.COLOR_"+color_model+"2BGR"
+                cvt_method = "cv2.COLOR_" + color_model + "2BGR"
                 self.img = cv2.cvtColor(self.img, eval(cvt_method))
             else:
                 print('Unknown color model, please manually transfer to BGR.')
         self.color_model = 'BGR'
 
-    def normalize(self):
-        """TODO: Normalize the image."""
+    def add_layer(self, layer = None,key='layer', type='feature'):
+        """Add a new key:ImgFeature/ImgMask instance to the self.layers_dict."""
+        if key == 'layer':
+            key = 'layer_' + str(len(self.layers_dict))
+        if layer is not None:
+            self.layers_dict[key] = layer
+        else:
+            if type=='feature':
+                if self.color_model == "GRAY":
+                    self.layers_dict[key] = ImgFeature2(self.img)
+                else:
+                    self.layers_dict[key] = ImgFeature3(self.img)
+            else:
+                if self.color_model == "GRAY":
+                    self.layers_dict[key] = ImgFeature2(self.img)
+                else:
+                    self.layers_dict[key] = ImgFeature3(self.img)
 
-    def add_feature(self, key):
-        """TODO: Add a new image_feature instance to the self.feature_dict by the key."""
+    def get_chessboard_calibrators(self, chessboard_img, ):
+        """
+        TODO: get calibrators using a chessboard image.
+        :param chessboard_img:
+        """
 
-    def __call__(self, method='and', **kwargs):
-        """TODO: Combine all features in the self.feature_dict by the method."""
+    def image_show(self):
+        helper.image_show(self.img)
+
+    def __call__(self, key1, key2, method='and'):
+        """
+        Return the Combination of 2 features in the self.layers_dict according to the method.
+        :param key1, key2: The keys of canvases to be combined.
+        :param method: Choose from("and", "or", "xor", "add")
+        """
+        try:
+            layer1 = self.layers_dict[key1]
+            layer2 = self.layers_dict[key2]
+        except:
+            print("Invalid keys!")
+            return
+        if method == 'and': return layer1&layer2
+        elif method == 'or': return layer1|layer2
+        elif method == 'xor': return layer1^layer2
+        elif method == 'add': return layer1+layer2
+        else:
+            print("Doesn't support such method, sorry.")
+            return
 
 
 def region_of_interest(img, vertices):
@@ -147,7 +283,7 @@
     return (lines, vertices)
 
 
-def sobel_mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255), dir_thresh=(0,np.pi/2)):
+def sobel_mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255), dir_thresh=(0, np.pi / 2)):
     """Use Sobel kernels to calculate the magnitude&direction of derivatives of an image.
 
     :input: img: image object RGB/GRAY
@@ -168,7 +304,7 @@
     d_img_mag_scaled = np.uint8(255 * d_img_mag / d_img_mag.max())
     d_img_mag_bin = (d_img_mag_scaled > mag_thresh[0]) & (d_img_mag_scaled < mag_thresh[1])
     d_img_dir_bin = (d_img_dir > dir_thresh[0]) & (d_img_dir < dir_thresh[1])
-    return np.uint8(d_img_mag_bin&d_img_dir_bin)*255
+    return np.uint8(d_img_mag_bin & d_img_dir_bin) * 255
 
 
 def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):
@@ -200,7 +336,7 @@
     line_list_r = []
 
     for hough_line in hough_line_list:
-        k = (hough_line[0][3]-hough_line[0][1])/(hough_line[0][2]-hough_line[0][0])
+        k = (hough_line[0][3] - hough_line[0][1]) / (hough_line[0][2] - hough_line[0][0])
         if k > kl_min and k < kl_max:
             line_list_l.append(hough_line)
         elif k > kr_min and k < kr_max:
@@ -220,7 +356,7 @@
             x_list_l.append(line[0][2])
             y_list_l.append(line[0][1])
             y_list_l.append(line[0][3])
-            k_l = (max(y_list_l)-min(y_list_l))/(max(x_list_l)-min(x_list_l))
+            k_l = (max(y_list_l) - min(y_list_l)) / (max(x_list_l) - min(x_list_l))
 
     if len(line_list_r) > 0:
         for line in line_list_r:
@@ -228,19 +364,18 @@
             x_list_r.append(line[0][2])
             y_list_r.append(line[0][1])
             y_list_r.append(line[0][3])
-            k_r = (max(y_list_r)-min(y_list_r))/(max(x_list_r)-min(x_list_r))
+            k_r = (max(y_list_r) - min(y_list_r)) / (max(x_list_r) - min(x_list_r))
 
     # To Do: Calculate the 2 x cordinates in the 2 lines to be returned
-    line_l = [0, h_img-1, 0, 0.6*h_img]
-    line_r = [w_img-1, h_img-1, w_img-1, 0.6*h_img]
+    line_l = [0, h_img - 1, 0, 0.6 * h_img]
+    line_r = [w_img - 1, h_img - 1, w_img - 1, 0.6 * h_img]
     if k_l != 0:
-        line_l[0] = min(x_list_l) - (line_l[1] - max(y_list_l))/k_l
-        line_l[2] = max(x_list_l) - (line_l[3] - min(y_list_l))/k_l
+        line_l[0] = min(x_list_l) - (line_l[1] - max(y_list_l)) / k_l
+        line_l[2] = max(x_list_l) - (line_l[3] - min(y_list_l)) / k_l
     if k_r != 0:
-        line_r[0] = min(x_list_r) + (line_r[1] - min(y_list_r))/k_r
-        line_r[2] = max(x_list_r) + (line_r[3] - max(y_list_r))/k_r
-    line_l = [map(int,line_l)]
-    line_r = [map(int,line_r)]
+        line_r[0] = min(x_list_r) + (line_r[1] - min(y_list_r)) / k_r
+        line_r[2] = max(x_list_r) + (line_r[3] - max(y_list_r)) / k_r
+    line_l = [map(int, line_l)]
+    line_r = [map(int, line_r)]
 
     return np.array([line_l, line_r])
-
